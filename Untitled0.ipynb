{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kris/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import networkx as nx\n",
    "import os \n",
    "import numpy as np\n",
    "import perm_matrix as pm\n",
    "import perms as p\n",
    "import sys\n",
    "import math\n",
    "import csv\n",
    "from gensim.models import word2vec\n",
    "ret_start_val = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kris/Desktop/ML_DeppWalk/Data/all_graph10/graph7.g6\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(7, 3), (7, 4), (7, 0), (7, 6)]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(8, 4), (8, 3), (8, 1), (8, 0)]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(6, 5)]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "0\n",
      "here\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(7, 3), (7, 5)]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "-1\n",
      "here\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(7, 1), (7, 3), (7, 3)]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "-1\n",
      "here\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "-1\n",
      "here\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "-1\n",
      "here\n",
      "{'000010000000000000000000000000000000100001000000010000000000000000000000000000000': 2006, '000000000000000000000000000000000000': 2009, '0000000000000000000000000000000000000000000000000': 2008, '0000000000000000000000000000000000000100000010100000010000000000': 2007, '0000010000000000000000000000000000010000000000000': 2004, '000000000100000000010000000000000000': 2003, '0000000000000000000010000001000000000000000011000': 2005, '000000001000000011000000011000000000000000011000000010000000000011011000111010000': 2001, '000000000010000000000000010000000000': 2002}\n",
      "hereroooopooooooooooooooooooooooooooooooooooooooooo\n",
      "{'000010000000000000000000000000000000100001000000010000000000000000000000000000000': 2006, '000000000000000000000000000000000000': 2009, '0000000000000000000000000000000000000000000000000': 2010, '0000000000000000000000000000000000000100000010100000010000000000': 2007, '0000010000000000000000000000000000010000000000000': 2004, '000000000100000000010000000000000000': 2003, '0000000000000000000010000001000000000000000011000': 2005, '000000001000000011000000011000000000000000011000000010000000000011011000111010000': 2001, '000000000010000000000000010000000000': 2002}\n",
      "0000000000000000000000000000000000000000000000000 2010\n",
      "['2006 2006 2010 2009 2006', '2006 2006 2010 2001 2003', '2006 2005 2010 2009 2001', '2001 2005 2010 2007 2006', '2003 2006 2010 2009 2009', '2002 2007 2010 2005 2001', '2002 2002 2010 2003 2009', '2009 2005 2010 2001 2001', '2002 2001 2010 2010 2007', '2004 2004 2010 2003 2009', '2005 2010 2010 2010 2007', '2001 2007 2010 2010 2002', '2007 2010 2010 2010 2003', '2004 2010 2010 2005 2007', '2010 2004 2010 2009 2006', '2007 2010 2010 2007 2001', '2003 2002 2010 2004 2005']\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(8, 4)]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "0\n",
      "here\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(7, 3), (7, 3), (7, 0), (7, 0)]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(7, 1), (7, 0), (7, 0)]\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "0\n",
      "here\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "herer\n",
      "{'000000000000000000000000000000001000000000001000100000000000000000000000000010000': 2012, '0000100000000000000000000010100000000010000000000': 2019, '0000010000101000000000100000000000011000000000000': 2014, '0000000000000000000010010000000000100100000010000000000100100010': 2016, '010000100000000000000000000000000000': 2013, '000001000000000000000001000000100100': 2018, '0010000000000010010000011000000000000000000000000': 2015, '010000100000000000000001000000000100': 2017, '000000000000000010000000001000000000': 2011}\n",
      "{'000000000000000000000000000000001000000000001000100000000000000000000000000010000': 2012, '0000100000000000000000000000100000000000000000000': 2020, '0000100000000000000000000010100000000010000000000': 2019, '0000010000101000000000100000000000011000000000000': 2014, '0000000000000000000010010000000000100100000010000000000100100010': 2016, '010000100000000000000000000000000000': 2013, '000001000000000000000001000000100100': 2018, '0010000000000010010000011000000000000000000000000': 2015, '010000100000000000000001000000000100': 2017, '000000000000000010000000001000000000': 2011}"
     ]
    }
   ],
   "source": [
    "#dir_name = os.listdir('../Data/all_graph10/')\n",
    "#file_name = [\"../Data/all_graph10/\"+i  for i in dir_name]\n",
    "#driver function for the program\n",
    "file_name = \"/home/kris/Desktop/ML_DeppWalk/Data/all_graph10/graph7.g6\"\n",
    "full_hash_table = []\n",
    "print file_name\n",
    "file_list = nx.read_graph6(file_name)\n",
    "d = 5 #context window size\n",
    "vocab = [] #vocab \"\"\"we migh have to save it to the disk and start again if size too big\"\"\"\n",
    "ret_start_val = 2000\n",
    "for i in range(0,len(file_list)):\n",
    "    present_neighbourhood = gen_neigbourhood(i)\n",
    "    start_val = max(0,ret_start_val)\n",
    "    ret_hash_table,key_mid = populate_table(i,start_val,present_neighbourhood)\n",
    "    ret_start_val = max(list(ret_hash_table.values()))\n",
    "    full_hash_table.append(ret_hash_table)\n",
    "    create_partial_vocab(present_neighbourhood,ret_hash_table,key_mid,d,vocab)\n",
    "    \n",
    "    \n",
    "nx.draw_networkx(file_list[7])\n",
    "print len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Create e-neigbourhood for any.. subgraph(e-neighbourhood is defined as 1 deletion(edge or node) as on dummy graph)\"\"\"\n",
    "def e_neighbourhood_node_del(G):\n",
    "    G_prime = G.copy()\n",
    "    print type(G_prime)\n",
    "    if len(G_prime.nodes()) > 0:\n",
    "        G_prime.remove_node(np.random.choice(G_prime.nodes()))\n",
    "    else:\n",
    "        print \"do nothing\"\n",
    "    return G_prime\n",
    "def e_neighbourhood_edge_del(G):\n",
    "    G_prime = G.copy()\n",
    "    print type(G_prime)\n",
    "    edges = G.edges()\n",
    "    #print np.random.choice(range(0,len(edges)-1))\n",
    "    print len(edges)-1 \n",
    "    if len(edges)-1 <= 0:\n",
    "        print \"here\"\n",
    "    else:\n",
    "        G_prime.remove_edge(*edges[np.random.choice(range(0,len(edges)-1))])\n",
    "    return G_prime\n",
    "def e_neighbourhood_node_add(G):\n",
    "    G_prime = G.copy()\n",
    "    print type(G_prime)\n",
    "    \"\"\"choose some random nodes in the graph to which we have to add a edge\"\"\"\n",
    "    label = len(G_prime)\n",
    "    nodes_attach = np.random.randint(label)\n",
    "    \"\"\"node neigh computed before so no self loops\"\"\"\n",
    "    node_neig = [np.random.choice(G_prime.nodes()) for _ in range(1,nodes_attach)]\n",
    "    G_prime.add_node(label)\n",
    "    a = [label for i in range(1,len(node_neig))]\n",
    "    val = zip(a,node_neig)\n",
    "    print val\n",
    "    G_prime.add_edges_from(val)\n",
    "    return G_prime\n",
    "def e_neighbourhood_edge_add(G):\n",
    "    G_prime = G.copy()\n",
    "    print type(G_prime)\n",
    "    \"\"\"choose 2 random nodes and a edge\"\"\"\n",
    "    n1 = np.random.choice(G_prime.nodes())\n",
    "    n2 = np.random.choice(G_prime.nodes())\n",
    "    if n1 is not n2:\n",
    "        \"\"\"graphs are simple so no self loop\"\"\"\n",
    "        print \"herer\"\n",
    "        G_prime.add_edge(n1,n2)\n",
    "    return G_prime\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"run some unit test\"\"\"\n",
    "#neigbourhood = e_neighbourhood_node_del(file_list[2])#pass\n",
    "#neigbourhood = e_neighbourhood_edge_del(file_list[2]) #pass\n",
    "#neigbourhood = e_neighbourhood_edge_add(file_list[2])#pass\n",
    "#neigbourhood = e_neighbourhood_node_add(file_list[2])#pass\n",
    "#nx.draw_networkx(neigbourhood)\n",
    "#add more boundary cases\n",
    "\"\"\"Now randomly choose the choices we from 1 to 4 and apply the eps times\"\"\"\n",
    "def gen_neigbourhood(k):\n",
    "    eps = 3\n",
    "    num_eps = 10 #number of eps neigbour hoods you want\n",
    "    neigbourhood = []\n",
    "    for j in range(1,num_eps):\n",
    "        indermitate_graph = file_list[k]\n",
    "        for i in range(1,3):\n",
    "            choice = np.random.choice(4)\n",
    "            if choice is 1:\n",
    "                indermitate_graph = e_neighbourhood_edge_del(indermitate_graph).copy()\n",
    "            elif choice is 2:\n",
    "                indermitate_graph = e_neighbourhood_node_del(indermitate_graph).copy()\n",
    "            elif choice is 3:\n",
    "                indermitate_graph = e_neighbourhood_node_add(indermitate_graph).copy()\n",
    "            else:\n",
    "                indermitate_graph = e_neighbourhood_edge_add(indermitate_graph).copy()\n",
    "        neigbourhood.append(indermitate_graph)\n",
    "    return neigbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "def seralize_matrix(matrix):\n",
    "    serialized_matrix = []\n",
    "    new_matrix = []\n",
    "    for i in range(0,len(matrix)) :\n",
    "        serialized_matrix.append(matrix[i][:])\n",
    "    #print serialized_matrix\n",
    "    for i in serialized_matrix:\n",
    "        i = i.tolist()\n",
    "        i = map(int,i)\n",
    "        i = map(str,i)\n",
    "        string = ''.join(i)\n",
    "        new_matrix.append(string)\n",
    "    return ''.join(new_matrix)\n",
    "def generate_all_isomorphic(graph):\n",
    "    \"\"\"\n",
    "    source for explanation math.stackexchange.com/questions/331233/showing-two-graphs-isomorphic-using-their-adjacency-matrices\n",
    "    \"\"\"\n",
    "    perm_matrix_list = perm_matrix(len(graph))\n",
    "    result = []\n",
    "    for i in perm_matrix_list:\n",
    "        result.append(np.dot(np.dot(i,graph),np.transpose(i)))\n",
    "    return result\n",
    "def perm_matrix(size):\n",
    "    \"\"\"\n",
    "    __params__:\n",
    "    size : size of the matrix you want to create\n",
    "    \"\"\"\n",
    "    org_matrix = np.identity(size)\n",
    "    string = [str(i) for i in range(0,size)]\n",
    "    all_strings =  p.perms(\"\".join(string))\n",
    "    all_matrix = []\n",
    "    for k,v in enumerate(all_strings):\n",
    "        matrix = np.zeros((size,size))\n",
    "        #perm matrix is square in cases of graphs adj matrix\n",
    "        #do this with list comprehension\n",
    "        for key,i in enumerate(v):\n",
    "            matrix[key][int(i)] = 1\n",
    "        all_matrix.append(matrix)\n",
    "    #print all_matrix[2]\n",
    "    return all_matrix\n",
    "def hashmap(graph,dictionary,counter):\n",
    "    if seralize_matrix(graph) in dictionary:\n",
    "        for key in dictionary.keys():\n",
    "            if seralize_matrix(graph) == key:\n",
    "                print \"hereroooopooooooooooooooooooooooooooooooooooooooooo\"\n",
    "                dictionary[key] = counter\n",
    "    else:\n",
    "        keys = generate_all_isomorphic(graph)\n",
    "        keys_serilized = []\n",
    "        for i in keys:\n",
    "            keys_serilized.append(seralize_matrix(i))\n",
    "        key = np.random.choice(len(keys_serilized))\n",
    "        dictionary[keys_serilized[key]] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def populate_table(k,starting_val,neigbourhood):\n",
    "    hash_table = {}\n",
    "    \"\"\"create a enrty for all neighbourhoods you found\"\"\"\n",
    "    for i in neigbourhood:\n",
    "        if len(hash_table.values()) is 0:\n",
    "            counter = starting_val + 1\n",
    "        else:\n",
    "            counter = max(hash_table.values()) + 1\n",
    "        hashmap(np.array(nx.to_numpy_matrix(i)),hash_table,counter)\n",
    "    counter = max(hash_table.values()) + 1\n",
    "    print hash_table\n",
    "    hashmap(np.array(nx.to_numpy_matrix(file_list[k])),hash_table,counter)\n",
    "    \"\"\"get the label for the original graph\"\"\"\n",
    "    print hash_table\n",
    "    key_mid = list(hash_table.keys())[list(hash_table.values()).index(counter)]\n",
    "    print key_mid,hash_table[key_mid]\n",
    "    return hash_table,key_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"okay so my idea is to create a new hashtable for all these subgraphs and generate corpus and then destroy them\"\"\"\n",
    "def create_partial_vocab(neigbourhood,hash_table,key_mid,d,vocab):\n",
    "    \"\"\"take 2*len(neigbourhood) such samples\"\"\"\n",
    "    for i in range(1,2*len(neigbourhood)):\n",
    "        choices = [np.random.choice(hash_table.values()) for i in range(1,d)]\n",
    "        choices.insert(int(math.floor(d/2)),hash_table[key_mid])\n",
    "        choices = map(str,choices)\n",
    "        vocab.append(\" \".join(choices))\n",
    "    print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "vocab = [i.split() for i in vocab]\n",
    "model = word2vec.Word2Vec(vocab, size=5, window=5, min_count=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_word2vec_format(\"./graph7.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74299026689315484"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity([\"1\"], [\"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = csv.writer(open('hashmap_.csv', 'wb'))\n",
    "for i in full_hash_table:\n",
    "    for key, value in i.items():\n",
    "        writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
